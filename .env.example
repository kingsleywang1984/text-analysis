# -----------------------------------------------------------------------------
# Text Analysis Service - Environment Configuration (.env.example)
# -----------------------------------------------------------------------------
#
# This file is a TEMPLATE. Copy it to `.env` and fill in values as needed.
# The application loads config from environment variables via `src/config.py`.
#
# Notes
# - Values are strings in env files; `src/config.py` converts them to int/float.
# - Comments here reflect validation/defaults enforced by `src/config.py`.
# - Base URLs should NOT include a trailing `/v1` (the code appends `/v1/...`).
# -----------------------------------------------------------------------------

# ==============================
# Embedding configuration
# ==============================
# EMBEDDING_PROVIDER
# - Purpose: choose how to embed text into vectors for clustering.
# - Allowed: tfidf | openai
# - Default (if omitted/empty): tfidf
EMBEDDING_PROVIDER=tfidf

# EMBEDDING_MODEL
# - Purpose: model identifier used by the selected embedding provider.
# - Required: YES (must be set even for TF-IDF mode; used as a config guard).
# - Examples:
#   - tfidf mode: tfidf (a sentinel string; not used by sklearn)
#   - openai mode: text-embedding-3-small (or any OpenAI-compatible embedding model)
EMBEDDING_MODEL=tfidf

# EMBEDDING_API_BASE_URL
# - Purpose: base URL for OpenAI-compatible embeddings endpoint.
# - Used when: EMBEDDING_PROVIDER=openai
# - Default (if omitted/empty): https://api.openai.com
# - IMPORTANT: do NOT include /v1 at the end.
EMBEDDING_API_BASE_URL=https://api.openai.com

# EMBEDDING_API_KEY
# - Purpose: API key used to call embedding provider.
# - Required when: EMBEDDING_PROVIDER=openai
EMBEDDING_API_KEY=

# EMBEDDING_API_TIMEOUT_SECONDS
# - Purpose: HTTP timeout for embedding API calls.
# - Type: float
# - Constraints: must be > 0
# - Default: 30
EMBEDDING_API_TIMEOUT_SECONDS=30

# EMBEDDING_API_BATCH_SIZE
# - Purpose: batch size for embedding API calls (number of texts per request).
# - Type: int
# - Constraints: must be a positive integer
# - Default: 256
EMBEDDING_API_BATCH_SIZE=256

# EMBEDDING_TFIDF_MAX_FEATURES
# - Purpose: cap TF-IDF vocabulary size for performance/memory.
# - Used when: EMBEDDING_PROVIDER=tfidf
# - Type: int (or empty to disable cap)
# - Constraints: if set, must be > 0
# - Default: empty (no explicit cap; sklearn chooses based on data)
EMBEDDING_TFIDF_MAX_FEATURES=2048

# EMBEDDING_TFIDF_NGRAM_MIN / EMBEDDING_TFIDF_NGRAM_MAX
# - Purpose: TF-IDF n-gram range.
# - Used when: EMBEDDING_PROVIDER=tfidf
# - Type: int
# - Constraints: min > 0 and max >= min
# - Defaults: min=1; max defaults to min if omitted/empty
EMBEDDING_TFIDF_NGRAM_MIN=1
EMBEDDING_TFIDF_NGRAM_MAX=2

# ==============================
# Clustering configuration
# ==============================
# CLUSTER_SIMILARITY_THRESHOLD
# - Purpose: minimum cosine similarity for grouping sentences into the same cluster.
# - Type: float
# - Required: YES
# - Constraints: must satisfy 0.0 < value <= 1.0
CLUSTER_SIMILARITY_THRESHOLD=0.55

# CLUSTER_MAX_CLUSTERS
# - Purpose: upper bound on number of clusters produced by the algorithm.
# - Type: int
# - Required: YES
# - Constraints: must be a positive integer
CLUSTER_MAX_CLUSTERS=10

# CLUSTER_OVERFLOW_STRATEGY
# - Purpose: how to handle sentences that would exceed max clusters / low similarity leftovers.
# - Allowed: OTHER | DROP
# - Default: OTHER
#   - OTHER: keep overflow sentences in an "Other" cluster
#   - DROP: discard overflow sentences from clustering output
CLUSTER_OVERFLOW_STRATEGY=OTHER

# ==============================
# Sentiment thresholds
# ==============================
# Sentiment logic requires: negative_threshold < 0 < positive_threshold
#
# SENTIMENT_STRONG_NEGATIVE_THRESHOLD
# - Purpose: threshold below which a sentence/cluster is classified as strongly negative.
# - Type: float
# - Required: YES
SENTIMENT_STRONG_NEGATIVE_THRESHOLD=-0.5

# SENTIMENT_POSITIVE_THRESHOLD
# - Purpose: threshold above which sentiment is positive.
# - Type: float
# - Required: YES
SENTIMENT_POSITIVE_THRESHOLD=0.3

# SENTIMENT_NEGATIVE_THRESHOLD
# - Purpose: threshold below which sentiment is negative.
# - Type: float
# - Required: YES
SENTIMENT_NEGATIVE_THRESHOLD=-0.2

# ==============================
# LLM output limits (schema sizing)
# ==============================
# These control how many bullet points the LLM is asked/allowed to return.
# Each pair must satisfy: min > 0 and min <= max
#
# CLUSTER_INSIGHTS_MIN / CLUSTER_INSIGHTS_MAX
# - Purpose: number of key insights per cluster (LLM output).
CLUSTER_INSIGHTS_MIN=2
CLUSTER_INSIGHTS_MAX=3

# COMPARISON_SIMILARITIES_MIN / COMPARISON_SIMILARITIES_MAX
# - Purpose: number of similarities in baseline vs comparison summary (LLM output).
COMPARISON_SIMILARITIES_MIN=1
COMPARISON_SIMILARITIES_MAX=3

# COMPARISON_DIFFERENCES_MIN / COMPARISON_DIFFERENCES_MAX
# - Purpose: number of differences in baseline vs comparison summary (LLM output).
COMPARISON_DIFFERENCES_MIN=1
COMPARISON_DIFFERENCES_MAX=3

# ==============================
# LLM configuration
# ==============================
# LLM_PROVIDER
# - Purpose: choose whether to call a real LLM or disable LLM calls entirely.
# - Allowed: none | openai_compatible
# - Default: none
#
# When LLM_PROVIDER != none, these must ALL be set:
# - LLM_BASE_URL
# - LLM_API_KEY
# - LLM_MODEL
LLM_PROVIDER=none

# LLM_BASE_URL
# - Purpose: base URL for an OpenAI-compatible chat completions API.
# - Example (OpenRouter): https://openrouter.ai/api
# - IMPORTANT: do NOT include /v1 at the end.
LLM_BASE_URL=

# LLM_API_KEY
# - Purpose: API key for the selected LLM provider.
LLM_API_KEY=

# LLM_MODEL
# - Purpose: model name passed to the provider (e.g. openai/gpt-4o-mini).
LLM_MODEL=

# LLM_TIMEOUT_SECONDS
# - Purpose: HTTP timeout for LLM calls.
# - Type: float
# - Required: YES (even if provider is none, config loader validates presence)
# - Constraints: must be > 0
LLM_TIMEOUT_SECONDS=8

# LLM_TEMPERATURE
# - Purpose: creativity / randomness for LLM output.
# - Type: float
# - Required: YES
# - Constraints: must be between 0.0 and 2.0
LLM_TEMPERATURE=0.2

# LLM_MAX_RETRIES
# - Purpose: how many times to retry transient LLM HTTP failures.
# - Type: int
# - Required: YES
# - Constraints: must be >= 0
LLM_MAX_RETRIES=1

# LLM_MAX_CLUSTERS
# - Purpose: LLM-first strategy safety bound; caps clusters considered for LLM summarization.
# - Type: int
# - Default: 10
# - Constraints: must be a positive integer
LLM_MAX_CLUSTERS=10

# LLM_REPRESENTATIVE_SENTENCES_PER_CLUSTER
# - Purpose: bound how many sentences per cluster are sent to the LLM (controls token cost).
# - Type: int
# - Default: 10
# - Constraints: must be a positive integer
LLM_REPRESENTATIVE_SENTENCES_PER_CLUSTER=10

